{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f51e735a-140d-4e03-b44d-2bc8eded0e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/novomics/work/TEA-graph:/work/Superpatch_network_construction'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONPATH\"] = \"/home/novomics/work/TEA-graph:\" + os.environ.get(\"PYTHONPATH\", \"\")\n",
    "os.environ.get(\"PYTHONPATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "beebbfe2-5c54-4d0e-a843-540dea275862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import openslide as osd\n",
    "from torchvision import transforms\n",
    "from torch_geometric.data import Data\n",
    "# from Superpatch_network_construction.EfficientNet import EfficientNet\n",
    "# from Superpatch_network_construction.superpatch_network_construction import false_graph_filtering\n",
    "from EfficientNet import EfficientNet\n",
    "from superpatch_network_construction import false_graph_filtering\n",
    "from skimage.filters import threshold_multiotsu\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import argparse\n",
    "import tifffile as tiff\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb77149-c350-47ae-95b0-30abd0077c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../Sample_data_for_demo/Novomics_TIF_Raw_WSI/.ipynb_checkpoints',\n",
       " '../Sample_data_for_demo/Novomics_TIF_Raw_WSI/T04-SHCN0046.tif']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Sample_data_for_demo/Novomics_TIF_Raw_WSI/T04-SHCN0046.tif: "
     ]
    }
   ],
   "source": [
    "device = torch.device(int('0') if torch.cuda.is_available() else \"cpu\")\n",
    "model_ft = EfficientNet.from_pretrained('efficientnet-b4', num_classes = 2)\n",
    "model_ft = model_ft.to(device)\n",
    "model_ft.eval()\n",
    "\n",
    "image_dir = '../Sample_data_for_demo/Novomics_TIF_Raw_WSI'\n",
    "files = files = os.listdir(image_dir)\n",
    "final_files = [os.path.join(image_dir, file) for file in files]\n",
    "final_files.sort(key=lambda f: os.stat(f).st_size, reverse=False)\n",
    "display(final_files)\n",
    "\n",
    "threshold =0.75\n",
    "spatial_threshold = 5.5\n",
    "\n",
    "def resize_tif_as_target_mpp(tif, target_mpp=2.0):\n",
    "    image = tif.asarray()\n",
    "    \n",
    "    try:\n",
    "        current_mpp = tif.pages[0].tags['XResolution'].value[1]\n",
    "        scaling_factor = current_mpp / target_mpp\n",
    "    except:\n",
    "        raise Exception('Error getting properties (Resolution)')\n",
    "    \n",
    "    resized_image = Image.fromarray(image).resize((int(image.shape[1] * scaling_factor), int(image.shape[0] * scaling_factor)))\n",
    "    print(f'mpp:{current_mpp} / scaling_factor:{scaling_factor}')\n",
    "    return resized_image, scaling_factor\n",
    "\n",
    "def supernode_generation(image, model_ft=model_ft, device=device, \n",
    "                         Argument={'threshold': 0.75, 'spatial_threshold': 5.5, 'imagesize':256}):\n",
    "    transform = transforms.Compose([\n",
    "                transforms.Resize(320),\n",
    "                transforms.CenterCrop(299),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225])\n",
    "                ])   \n",
    "    \n",
    "    threshold = Argument.get('threshold')\n",
    "    spatial_threshold = Argument.get('spatial_threshold')\n",
    "\n",
    "    with tiff.TiffFile(image) as tif:\n",
    "        print(f'{image}:', end=' ')\n",
    "        resized_image, scaling_factor = resize_tif_as_target_mpp(tif)\n",
    "        \n",
    "        tif_native_arr = tif.asarray()\n",
    "        tif_native_img = Image.fromarray(np.uint8(tif_native_arr)).convert('L')\n",
    "        img = np.array(tif_native_img)\n",
    "\n",
    "        thresholds = threshold_multiotsu(img)\n",
    "        regions = np.digitize(img, bins=thresholds)\n",
    "        regions[regions == 1] = 0\n",
    "        regions[regions == 2] = 1\n",
    "        thresh_otsu = regions\n",
    "        \n",
    "        plt.imshow(thresh_otsu)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        imagesize = Argument.get('imagesize')\n",
    "        resampled_size = int(imagesize / scaling_factor)\n",
    "        display(resampled_size)\n",
    "        \n",
    "        Height, Width = tif.pages[0].shape\n",
    "        # Height = tif.pages[0].image_height\n",
    "        num_row = int(Height/imagesize) + 1\n",
    "        num_col = int(Width/imagesize) + 1\n",
    "        x_list = []\n",
    "        y_list = []\n",
    "        feature_list = []\n",
    "        x_y_list = []\n",
    "        counter = 0\n",
    "        inside_counter = 0\n",
    "        temp_patch_list = []\n",
    "        temp_x = []\n",
    "        temp_y = []\n",
    "        \n",
    "        with tqdm(total = num_row * num_col) as pbar_image:\n",
    "            for i in range(0, num_col):\n",
    "                for j in range(0, num_row):\n",
    "                    \n",
    "                    if thresh_otsu.shape[1] >= (i+1)*resampled_size:\n",
    "                        if thresh_otsu.shape[0] >= (j+1)*resampled_size:\n",
    "                            cut_thresh = thresh_otsu[j*resampled_size:(j+1)*resampled_size, i*resampled_size:(i+1)*resampled_size]\n",
    "                        else:\n",
    "                            cut_thresh = thresh_otsu[(j)*resampled_size:thresh_otsu.shape[0], i*resampled_size:(i+1)*resampled_size]\n",
    "                    else:\n",
    "                        if thresh_otsu.shape[0] >= (j+1)*resampled_size:\n",
    "                            cut_thresh = thresh_otsu[j*resampled_size:(j+1)*resampled_size, (i)*resampled_size:thresh_otsu.shape[1]]\n",
    "                        else:\n",
    "                            cut_thresh = thresh_otsu[(j)*resampled_size:thresh_otsu.shape[0], (i)*resampled_size:thresh_otsu.shape[1]]\n",
    "                             \n",
    "                    if np.mean(cut_thresh) > 0.75:\n",
    "                        pbar_image.update()\n",
    "                        pass\n",
    "    # plt.imshow(resized_image)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "    \n",
    "\n",
    "supernode_generation(final_files[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c583b7-07a6-40bb-afb2-64409c2eca35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
